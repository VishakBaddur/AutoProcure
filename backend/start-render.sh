#!/bin/bash

echo "ğŸš€ Starting AutoProcure backend on Render..."

# Install Ollama if not already installed
if ! command -v ollama &> /dev/null; then
    echo "ğŸ“¦ Installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
fi

# Start Ollama server
echo "ğŸ”§ Starting Ollama server..."
ollama serve &
OLLAMA_PID=$!

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to be ready..."
sleep 10

# Check if Mistral model exists, if not download it
echo "ğŸ¤– Checking Mistral model..."
if ! ollama list | grep -q "mistral"; then
    echo "ğŸ“¥ Downloading Mistral model..."
    ollama pull mistral
else
    echo "âœ… Mistral model already available"
fi

# Wait a bit more for everything to be ready
sleep 5

echo "ğŸ¯ Starting FastAPI application..."
cd backend && uvicorn app.main:app --host 0.0.0.0 --port $PORT 